{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZebTiNumKj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "pd.options.mode.chained_assignment = None\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90nqGJthZnZq",
        "colab_type": "code",
        "outputId": "903fc083-b1ac-43e8-b182-10eb929e7c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/alldata.csv')\n",
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 103624 entries, 0 to 103623\n",
            "Data columns (total 7 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   Unnamed: 0    103624 non-null  int64  \n",
            " 1   corpus_index  103624 non-null  int64  \n",
            " 2   date          103624 non-null  object \n",
            " 3   direction     103624 non-null  object \n",
            " 4   ex_return     101996 non-null  float64\n",
            " 5   ticker        103624 non-null  object \n",
            " 6   whole         103624 non-null  object \n",
            "dtypes: float64(1), int64(2), object(4)\n",
            "memory usage: 5.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItWL69xiZBbU",
        "colab_type": "code",
        "outputId": "6d9c8ef7-478e-4ac8-b2f9-3218e6419756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "# preprocessing data: change format\n",
        "\n",
        "\n",
        "\n",
        "df = df.dropna()\n",
        "df['date'] = pd.to_datetime(df.date)\n",
        "\n",
        "df['dir'] = df['direction'].apply(lambda x: 1 if x == 'up' else -1)\n",
        "df = df.reset_index()\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>corpus_index</th>\n",
              "      <th>date</th>\n",
              "      <th>direction</th>\n",
              "      <th>ex_return</th>\n",
              "      <th>ticker</th>\n",
              "      <th>whole</th>\n",
              "      <th>dir</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>62740</td>\n",
              "      <td>16</td>\n",
              "      <td>2001-01-25</td>\n",
              "      <td>down</td>\n",
              "      <td>-5.80473</td>\n",
              "      <td>LLY</td>\n",
              "      <td>on that managed short term symptoms are then b...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>62737</td>\n",
              "      <td>13</td>\n",
              "      <td>2001-01-25</td>\n",
              "      <td>down</td>\n",
              "      <td>-5.80473</td>\n",
              "      <td>LLY</td>\n",
              "      <td>is from Steve Tie's line from Merrill Lynch. P...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>62730</td>\n",
              "      <td>6</td>\n",
              "      <td>2001-01-25</td>\n",
              "      <td>down</td>\n",
              "      <td>-5.80473</td>\n",
              "      <td>LLY</td>\n",
              "      <td>6%. Excluding the effect of exchange rates, an...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>62739</td>\n",
              "      <td>15</td>\n",
              "      <td>2001-01-25</td>\n",
              "      <td>down</td>\n",
              "      <td>-5.80473</td>\n",
              "      <td>LLY</td>\n",
              "      <td>year when we will be losing execution of the m...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>62729</td>\n",
              "      <td>5</td>\n",
              "      <td>2001-01-25</td>\n",
              "      <td>down</td>\n",
              "      <td>-5.80473</td>\n",
              "      <td>LLY</td>\n",
              "      <td>last year totalling $419 million. The decline ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  Unnamed: 0  ...                                              whole dir\n",
              "0      0       62740  ...  on that managed short term symptoms are then b...  -1\n",
              "1      1       62737  ...  is from Steve Tie's line from Merrill Lynch. P...  -1\n",
              "2      2       62730  ...  6%. Excluding the effect of exchange rates, an...  -1\n",
              "3      3       62739  ...  year when we will be losing execution of the m...  -1\n",
              "4      4       62729  ...  last year totalling $419 million. The decline ...  -1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4GQBoku8keV",
        "colab_type": "code",
        "outputId": "8783ec02-b0e0-4abe-878d-5f11b88485aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "df.groupby(['date', 'ticker']).first()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>corpus_index</th>\n",
              "      <th>direction</th>\n",
              "      <th>ex_return</th>\n",
              "      <th>whole</th>\n",
              "      <th>dir</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th>ticker</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2001-01-25</th>\n",
              "      <th>LLY</th>\n",
              "      <td>0</td>\n",
              "      <td>62740</td>\n",
              "      <td>16</td>\n",
              "      <td>down</td>\n",
              "      <td>-5.804730</td>\n",
              "      <td>on that managed short term symptoms are then b...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-03-19</th>\n",
              "      <th>PAYX</th>\n",
              "      <td>17</td>\n",
              "      <td>80229</td>\n",
              "      <td>9</td>\n",
              "      <td>up</td>\n",
              "      <td>2.379739</td>\n",
              "      <td>a short period of time, but over time, you're ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-04-03</th>\n",
              "      <th>BBY</th>\n",
              "      <td>32</td>\n",
              "      <td>13919</td>\n",
              "      <td>22</td>\n",
              "      <td>up</td>\n",
              "      <td>3.539244</td>\n",
              "      <td>a modest selection of consumer electronics. So...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-04-04</th>\n",
              "      <th>THC</th>\n",
              "      <td>55</td>\n",
              "      <td>100259</td>\n",
              "      <td>16</td>\n",
              "      <td>down</td>\n",
              "      <td>-0.898221</td>\n",
              "      <td>but we keep coming back to the demographics, a...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-04-11</th>\n",
              "      <th>HOG</th>\n",
              "      <td>76</td>\n",
              "      <td>50069</td>\n",
              "      <td>13</td>\n",
              "      <td>up</td>\n",
              "      <td>0.650465</td>\n",
              "      <td>quarter and that's just a time issue that went...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">2005-12-22</th>\n",
              "      <th>GIS</th>\n",
              "      <td>103502</td>\n",
              "      <td>45911</td>\n",
              "      <td>13</td>\n",
              "      <td>up</td>\n",
              "      <td>1.705193</td>\n",
              "      <td>General Mills, Inc. - EVP, CFO   [50]  Thank ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PAYX</th>\n",
              "      <td>103532</td>\n",
              "      <td>80689</td>\n",
              "      <td>2</td>\n",
              "      <td>down</td>\n",
              "      <td>-2.484627</td>\n",
              "      <td>workers' compensation insurance risk. And were...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SLR</th>\n",
              "      <td>103509</td>\n",
              "      <td>93443</td>\n",
              "      <td>4</td>\n",
              "      <td>up</td>\n",
              "      <td>0.215506</td>\n",
              "      <td>of 2%, and representing 18% of total revenue. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TMO</th>\n",
              "      <td>103523</td>\n",
              "      <td>101980</td>\n",
              "      <td>0</td>\n",
              "      <td>down</td>\n",
              "      <td>-4.708141</td>\n",
              "      <td>Operator   [1]  Good morning, ladies and gentl...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005-12-28</th>\n",
              "      <th>CELG</th>\n",
              "      <td>103614</td>\n",
              "      <td>20895</td>\n",
              "      <td>9</td>\n",
              "      <td>up</td>\n",
              "      <td>2.586075</td>\n",
              "      <td>A question on the myeloma sNDA that will be go...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6081 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    index  ...  dir\n",
              "date       ticker          ...     \n",
              "2001-01-25 LLY          0  ...   -1\n",
              "2001-03-19 PAYX        17  ...    1\n",
              "2001-04-03 BBY         32  ...    1\n",
              "2001-04-04 THC         55  ...   -1\n",
              "2001-04-11 HOG         76  ...    1\n",
              "...                   ...  ...  ...\n",
              "2005-12-22 GIS     103502  ...    1\n",
              "           PAYX    103532  ...   -1\n",
              "           SLR     103509  ...    1\n",
              "           TMO     103523  ...   -1\n",
              "2005-12-28 CELG    103614  ...    1\n",
              "\n",
              "[6081 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65fLm-VOnGcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train test split\n",
        "\n",
        "val_size = int(df.shape[0] * 0.15)\n",
        "test_size = int(df.shape[0] * 0.15)\n",
        "train_size = int(df.shape[0] * 0.7)\n",
        "\n",
        "train_ticker, train_date, train_corp, train_texts, train_ret, train_dir = df.ticker[:train_size], df.date[:train_size], df.corpus_index[:train_size], df.whole[:train_size], df.ex_return[:train_size], df.dir[:train_size]\n",
        "val_ticker, val_date, val_corp, val_texts, val_ret, val_dir = df.ticker[train_size:train_size+val_size], df.date[train_size:train_size+val_size], df.corpus_index[train_size:train_size+val_size], df.whole[train_size:train_size+val_size], df.ex_return[train_size:train_size+val_size], df.dir[train_size:train_size+val_size]\n",
        "test_ticker, test_date, test_corp, test_texts, test_ret, test_dir = df.ticker[train_size+val_size:], df.date[train_size+val_size:], df.corpus_index[train_size+val_size:], df.whole[train_size+val_size:], df.ex_return[train_size+val_size:], df.dir[train_size+val_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlcuRuismWqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocess data: vectorize it\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def tfidf(data, max_features):\n",
        "    import nltk\n",
        "    try: \n",
        "      stop_words = stopwords.words('english')\n",
        "    except:\n",
        "      nltk.download('stopwords')\n",
        "      stop_words = stopwords.words('english')\n",
        "\n",
        "    tfidf = TfidfVectorizer(stop_words = stop_words, max_features = max_features)\n",
        "    model = tfidf.fit(data)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H14DCLGsmwCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Mba8zD5cJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_score(y_true, y_pred): \n",
        "\n",
        "    # Calculate accuracy of the model's prediction\n",
        "    \"\"\"\n",
        "    YOUR CODE GOES HERE\n",
        "    \"\"\"\n",
        "    true = 0\n",
        "    total = int(len(y_true))\n",
        "    for i in range(len(y_true)):\n",
        "      if y_true[i] == y_pred[i]:\n",
        "        true += 1\n",
        "    \n",
        "    accuracy = float(true)/float(total)\n",
        "    return accuracy\n",
        "\n",
        "def f1_score(y_true, y_pred): \n",
        "    tp=0\n",
        "    fp=0\n",
        "    tn=0\n",
        "    fn=0\n",
        "    for i in range(0,len(y_true)):\n",
        "      if(y_true[i]==1 and y_pred[i]==1):\n",
        "        tp+=1\n",
        "      elif(y_true[i]==-1 and y_pred[i]==1):\n",
        "        fp+=1\n",
        "      elif(y_true[i]==-1 and y_pred[i]==-1):\n",
        "        tn+=1\n",
        "      elif(y_true[i]==1 and y_pred[i]==-1):\n",
        "        fn+=1\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/(tp+fn)\n",
        "    f1 = (2*precision*recall) / (precision+recall)\n",
        "    return f1\n",
        "\n",
        "\n",
        "def get_accuracy(y_pred, df, set):\n",
        "\n",
        "  data_set = {'train' : df[:train_size], 'val' : df[train_size:train_size+val_size], 'test' : df[train_size+val_size:]}\n",
        "  df1 = data_set[set]\n",
        "\n",
        "  df1['pred'] = y_pred\n",
        "  agg_pred = df1.groupby(['ticker', 'date']).sum()['pred'].apply(lambda x: 1 if x > 0 else -1).values.tolist()\n",
        "  true_pred = df1.groupby(['ticker', 'date']).first().dir.values.tolist()\n",
        "  acc = accuracy_score(true_pred,agg_pred)\n",
        "  f1 = f1_score(true_pred, agg_pred)\n",
        "  return acc, f1\n",
        "\n",
        "\n",
        "def get_r2_mse(y_pred, df, set):\n",
        "\n",
        "  data_set = {'train' : df[:train_size], 'val' : df[train_size:train_size+val_size], 'test' : df[train_size+val_size:]}\n",
        "  df1 = data_set[set]\n",
        "\n",
        "  df1['pred'] = y_pred\n",
        "  agg_pred = df1.groupby(['ticker', 'date']).mean()['pred'].values.tolist()\n",
        "  true_pred = df1.groupby(['ticker', 'date']).first().ex_return.values.tolist()\n",
        "\n",
        "\n",
        "  return r2_score(true_pred, agg_pred), mean_squared_error(true_pred, agg_pred)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp_yoIdwolUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform data\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "def surprise_me(train_texts, val_texts, test_texts, df, max_features, alpha):\n",
        "    vectorizer = tfidf(train_texts, max_features = max_features)\n",
        "    X_train= vectorizer.transform(train_texts)\n",
        "    X_val= vectorizer.transform(val_texts)\n",
        "    X_test= vectorizer.transform(test_texts)\n",
        "\n",
        "\n",
        "    y_train = np.array(train_dir)\n",
        "    y_val = np.array(val_dir)\n",
        "    y_test = np.array(test_dir)\n",
        "\n",
        "\n",
        "    model = ComplementNB(alpha = alpha)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make prediction using the trained model\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    train_acc = accuracy_score(y_train_pred, y_train)\n",
        "    train_f1 = f1_score(y_train_pred, y_train)\n",
        "    val_acc = accuracy_score(y_val_pred, y_val) \n",
        "    val_f1 = f1_score(y_val_pred, y_val)\n",
        "    test_acc = accuracy_score(y_test_pred, y_test)\n",
        "    test_f1 = f1_score(y_test_pred, y_test)\n",
        "    \n",
        "    report = pd.DataFrame({'acc': [train_acc,val_acc,test_acc], 'f1':[train_f1, val_f1,test_f1]})\n",
        "    report.index = ['train', 'val', 'test']\n",
        "\n",
        "    print('surprise mf!')\n",
        "    print('classification with Naive Bayes')\n",
        "    return report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNV8a0946Bne",
        "colab_type": "code",
        "outputId": "fb237492-aaae-402c-cc4e-1356f7dd5997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "surprise_me(train_texts, val_texts, test_texts, df, 500, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-9f222e83d9b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msurprise_me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-d6c268b1747a>\u001b[0m in \u001b[0;36msurprise_me\u001b[0;34m(train_texts, val_texts, test_texts, df, max_features, alpha)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msurprise_me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                    \"be removed in 0.24.\")\n\u001b[1;32m   1897\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8awqwKBBYW7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTozu0_WDuDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RejmOAVJIUJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "def get_scores(train_texts, val_texts, test_texts, df, max_features_list):\n",
        "    score = []\n",
        "    for x in tqdm(max_features_list):\n",
        "      for a in alpha_list:\n",
        "        vectorizer = tfidf(train_texts, max_features = x)\n",
        "        X_train= vectorizer.transform(train_texts)\n",
        "        X_val= vectorizer.transform(val_texts)\n",
        "\n",
        "\n",
        "        y_train = np.array(train_dir)\n",
        "        y_val = np.array(val_dir)\n",
        "\n",
        "        model = ComplementNB(alpha = a)\n",
        "        model.fit(X_train, y_train)\n",
        "        # Make prediction using the trained model\n",
        "        y_val_pred = model.predict(X_val)\n",
        "        val_acc = accuracy_score(y_val_pred, y_val) \n",
        "        val_f1 = f1_score(y_val_pred, y_val)\n",
        "        score.append([x,a, val_acc, val_f1])\n",
        "    return score\n",
        "\n",
        "def get_top(features, alpha, score):\n",
        "    highest_score = sorted(score, reverse = True)[0]\n",
        "    highest_idx = score.index(highest_score)\n",
        "    max_feature_idx = highest_idx//len(features)\n",
        "    # max_feature_idx = np.floor(float(highest_idx)/float(len(features)))\n",
        "    a_idx = highest_idx % len(features)\n",
        "    return features[max_feature_idx], alpha[a_idx], highest_score\n",
        "    \n",
        "\n",
        "def show_me_max_feature(max_features_list,alpha_list, alpha, accs, f1s):\n",
        "    max_features_big_list = []\n",
        "    alpha_big_list = []\n",
        "\n",
        "    for x in max_features_list:\n",
        "      for a in alpha_list:\n",
        "        max_features_big_list.append(x)\n",
        "        alpha_big_list.append(a)\n",
        "\n",
        "    df = pd.DataFrame({'max_feature': max_features_big_list, 'alpha': alpha_big_list, \n",
        "                       'accs' : accs, 'f1s' : f1s})\n",
        "    data = df[df['alpha'] == alpha].sort_values(by = 'max_feature')\n",
        "    accs = data.accs\n",
        "    f1s = data.f1s\n",
        "    plt.plot(max_features_list, accs,'r--', max_features_list,f1s)\n",
        "    plt.legend(['acc', 'f1'])\n",
        "    plt.xlabel('max_features')\n",
        "    plt.ylabel('scores')\n",
        "    plt.show()\n",
        "    \n",
        "def show_me_alpha(max_feature_list, alpha_list, max_feature, accs, f1s):\n",
        "    max_features_big_list = []\n",
        "    alpha_big_list = []\n",
        "\n",
        "    for x in max_features_list:\n",
        "      for a in alpha_list:\n",
        "        max_features_big_list.append(x)\n",
        "        alpha_big_list.append(a)\n",
        "\n",
        "    df = pd.DataFrame({'max_feature': max_features_big_list, 'alpha_list': alpha_big_list, \n",
        "                       'accs' : accs, 'f1s' : f1s})\n",
        "    data = df[df['max_feature'] == max_feature].sort_values(by = 'alpha_list')\n",
        "\n",
        "    accs = data.accs\n",
        "\n",
        "    f1s = data.f1s\n",
        "    plt.plot(alpha_list, accs,'r--', alpha_list,f1s)\n",
        "    plt.legend(['acc', 'f1'])\n",
        "    plt.xlabel('alpha')\n",
        "    plt.ylabel('scores')\n",
        "    plt.show()\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtXLIitIKW1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features_list = [500, 1000,1500,2000,2500,3000]\n",
        "alpha_list = [0.0001, 0.001, 0.01, 0.1]\n",
        "clf_report = get_scores(train_texts, val_texts, test_texts, df, max_features_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3prB_etP4d9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_result = pd.DataFrame.from_records(clf_report)\n",
        "clf_result.sort_values(by = 2, ascending=False).head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Iuz6_YR-gQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "surprise_me(train_texts, val_texts, test_texts, df, 3000, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGoftxg507H6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def r2_score(y_true, y_pred):\n",
        "  sst = 0\n",
        "  ssr = 0\n",
        "  mu = np.array(y_true).mean()\n",
        "  for i in range(len(y_true)):\n",
        "    ssr += (y_pred[i] - y_true[i])**2\n",
        "    sst += (y_true[i] - mu)**2\n",
        "  return round((1 - ssr/sst), 4)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwtC2kqx_PTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "def better_not_surprise_me(train_texts, val_texts, test_texts, df, max_features, alpha):\n",
        "    vectorizer = tfidf(train_texts, max_features = max_features)\n",
        "    X_train= vectorizer.transform(train_texts)\n",
        "    X_val= vectorizer.transform(val_texts)\n",
        "    X_test= vectorizer.transform(test_texts)\n",
        "\n",
        "    y_train = np.array(train_ret)\n",
        "    y_val = np.array(val_ret)\n",
        "    y_test = np.array(test_ret)\n",
        "\n",
        "\n",
        "    model = Lasso(alpha = alpha)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make prediction using the trained model\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    train_r2 = round(r2_score( y_train, y_train_pred), 3)\n",
        "    train_mse = mean_squared_error( y_train, y_train_pred)\n",
        "    val_r2 = round(r2_score( y_val, y_val_pred), 3)\n",
        "    val_mse = mean_squared_error( y_val, y_val_pred)\n",
        "    test_r2 = round(r2_score( y_test, y_test_pred), 3)\n",
        "    test_mse = mean_squared_error( y_test, y_test_pred)\n",
        "\n",
        "    report = pd.DataFrame({'r2': [train_r2,val_r2,test_r2], 'mse': [train_mse, val_mse, test_mse]})\n",
        "    report.index = ['train', 'val', 'test']\n",
        "\n",
        "    print('surprise mf!')\n",
        "    return report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQYAsmucUSTH",
        "colab_type": "code",
        "outputId": "cb3da1d7-1b8a-4a61-f28a-9e9b1daa0956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "better_not_surprise_me(train_texts, val_texts, test_texts, df, 3000, 0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-3.1822455789065545e+33\n",
            "0.0\n",
            "surprise mf!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>r2</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>-3.182246e+33</td>\n",
              "      <td>9.806051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>11.830985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>-3.764515e+33</td>\n",
              "      <td>11.600308</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 r2        mse\n",
              "train -3.182246e+33   9.806051\n",
              "val    0.000000e+00  11.830985\n",
              "test  -3.764515e+33  11.600308"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqtqVlPCUWWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "def get_scores2(train_texts, val_texts, test_texts, df, max_features_list):\n",
        "    scores = []\n",
        "    mse = []\n",
        "    for max_features in tqdm(max_features_list):\n",
        "      for a in alpha_list:\n",
        "        vectorizer = tfidf(train_texts, max_features = max_features)\n",
        "        X_train= vectorizer.transform(train_texts)\n",
        "        X_val= vectorizer.transform(val_texts)\n",
        "\n",
        "\n",
        "\n",
        "        y_train = np.array(train_ret)\n",
        "        y_val = np.array(val_ret)\n",
        "\n",
        "\n",
        "      \n",
        "        model = Lasso(alpha = a)\n",
        "        model.fit(X_train, y_train)\n",
        "        # Make prediction using the trained model\n",
        "        y_val_pred = model.predict(X_val)\n",
        "        r2 = r2_score(y_val,y_val_pred)\n",
        "        mse = mean_squared_error( y_val, y_val_pred)\n",
        "        scores.append([max_features, a, r2, mse])\n",
        "\n",
        "    return scores\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDzIxLEeUjxh",
        "colab_type": "code",
        "outputId": "90c50210-3586-4b8d-b5b7-670a0d252571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "max_features_list = np.linspace(200, 1000, 5, dtype = int)\n",
        "max_features_list = [250, 1000,1500,2000,2500,3000]\n",
        "alpha_list = [0.0001, .001, 0.01, 0.1]\n",
        "scores = get_scores2(train_texts, val_texts, test_texts, df, max_features_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 1/6 [02:48<14:02, 168.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 2/6 [05:51<11:31, 172.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 3/6 [08:59<08:52, 177.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 4/6 [12:13<06:04, 182.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 5/6 [15:34<03:07, 187.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 6/6 [19:18<00:00, 193.00s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwf-vfdyOr6I",
        "colab_type": "code",
        "outputId": "7ec6d4d6-820b-45bf-a036-b0e9f4de05b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "\n",
        "reg_result = pd.DataFrame.from_records(scores)\n",
        "reg_result.sort_values(by = 2, ascending=False).head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3000</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>-0.0596</td>\n",
              "      <td>11.709455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2500</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>-0.0602</td>\n",
              "      <td>11.715217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1000</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>-0.0612</td>\n",
              "      <td>11.726831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1500</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>-0.0621</td>\n",
              "      <td>11.736115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>250</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>-0.0622</td>\n",
              "      <td>11.737554</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0       1       2          3\n",
              "21  3000  0.0010 -0.0596  11.709455\n",
              "17  2500  0.0010 -0.0602  11.715217\n",
              "5   1000  0.0010 -0.0612  11.726831\n",
              "9   1500  0.0010 -0.0621  11.736115\n",
              "0    250  0.0001 -0.0622  11.737554"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XtToQkw0c6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Jl7ofP_5jp",
        "colab_type": "code",
        "outputId": "6731afac-adc0-4b42-fb36-56786937ff49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "better_not_surprise_me(train_texts, val_texts, test_texts, df, 3000, 0.0001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "surprise mf!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>r2</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>0.098</td>\n",
              "      <td>8.847331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>-0.076</td>\n",
              "      <td>11.896247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>-0.073</td>\n",
              "      <td>11.747469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          r2        mse\n",
              "train  0.098   8.847331\n",
              "val   -0.076  11.896247\n",
              "test  -0.073  11.747469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMXqjKwZcDvF",
        "colab_type": "code",
        "outputId": "4c3c1f39-5ca3-4830-e162-0f1756415a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "r2_score([1,2,3], [0,1,2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze2xOvB-9ynP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = [1,2,3]\n",
        "y_pred = [1,1,2]\n",
        "sst = 0\n",
        "ssr = 0\n",
        "mu = np.array(y_true).mean()\n",
        "for i in range(len(y_true)):\n",
        "  ssr += (y_pred[i] - y_true[i])**2\n",
        "  sst += (y_true[i] - mu)**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1qqB9440qVV",
        "colab_type": "code",
        "outputId": "b3cd2a19-729b-4288-9b12-6c5c073eab86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "ssr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cjPUaRT2XFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}